# Awesome-accountable-LLM

- Interpretability
- Fairness
- Privacy
- Robustness
- Security
- ...

## LLM-generated Text Detection

- A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions. [[Github](https://github.com/junchaoIU/LLM-generated-Text-Detection)] [[arXiv](https://arxiv.org/abs/2310.14724)]
- A Survey on Detection of LLMs-Generated Content. [[Github](https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection)] [[arXiv](https://arxiv.org/abs/2310.15654v1)]

## Interpretability LLM

- Explainability for Large Language Models: A Survey. [[arXiv](https://arxiv.org/abs/2309.01029)]

## Security LLM

- Constitutional AI: Harmlessness from AI Feedback. [[arXiv](https://arxiv.org/abs/2212.08073)]
- Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. [[arXiv](https://arxiv.org/abs/2309.01219)]
- A Survey of Hallucination in Large Foundation Models. [[arXiv](https://arxiv.org/abs/2309.05922)]
- Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment. [[arXiv](https://arxiv.org/abs/2308.05374)]
- Towards Better Chain-of-Thought Prompting Strategies: A Survey. [[arXiv](https://arxiv.org/abs/2308.05374)]
